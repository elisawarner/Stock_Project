{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Author: Elisa Warner\n",
    "Created: 4/16/2019\n",
    "\n",
    "Purpose: Check results of SVM against stock data\n",
    "\n",
    "Change Record:\n",
    "6/11/2019 Made Time-Cross Validation be non-overlapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Table Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "## Create confusion table\n",
    "###########################\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def prediction_box(predictions, ground_truth):\n",
    "    ## results\n",
    "    result = {'tp':0, 'fp':0, 'tn':0, 'fn':0}\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        #print(pred_test[i], y[i])\n",
    "        if predictions[i] == ground_truth[i] and ground_truth[i] == 1:\n",
    "            result['tp'] = result.get('tp', 0) + 1\n",
    "        elif predictions[i] == ground_truth[i] and ground_truth[i] == 0:\n",
    "            result['tn'] = result.get('tn', 0) + 1\n",
    "        elif predictions[i] != ground_truth[i] and ground_truth[i] == 1:\n",
    "            result['fn'] = result.get('fn', 0) + 1\n",
    "        else:\n",
    "            result['fp'] = result.get('fp', 0) + 1\n",
    "\n",
    "    m = np.array([[result['tp'], result['fn']],[result['fp'],result['fn']]])\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(m, cmap='Pastel1')\n",
    "    \n",
    "    for i in range(m.shape[0]):\n",
    "        for j in range(m.shape[1]):\n",
    "            plt.text(j, i, \"{:.2f}\".format(m[i,j]), ha=\"center\", va=\"center\")\n",
    "            plt.title('Predictions for Test Set')\n",
    "            ax.set_xticks([0, 1])\n",
    "            ax.set_yticks([0, 1])\n",
    "            ax.set_xticklabels([1, 0])\n",
    "            ax.set_yticklabels([1, 0])\n",
    "            plt.ylabel('Ground Truth')\n",
    "            plt.xlabel('Prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_missing(df):\n",
    "    for col in list(df):\n",
    "        colvals = df[col].values\n",
    "        new_colvals = []\n",
    "        for i in range(len(colvals)):\n",
    "            if colvals[i] == '.':\n",
    "                print('Missing found')\n",
    "                new_colvals.append(colvals[i-1])\n",
    "            elif pd.isnull(colvals[i]):\n",
    "                print('nan found')\n",
    "                new_colvals.append(colvals[i-1])\n",
    "            else:\n",
    "                new_colvals.append(colvals[i])\n",
    "        df[col] = new_colvals\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_missing_horz(df):\n",
    "    new_df = pd.DataFrame()\n",
    "    for i in range(df.shape[0]):\n",
    "        row = list(df.iloc[i].values)\n",
    "\n",
    "        if '.' in row:\n",
    "            idx_list = [i for i in range(len(row)) if row[i] == ('.')]\n",
    "            for idx in idx_list:\n",
    "                row[idx] = row[idx - 1]\n",
    "\n",
    "        idx_list = [i for i in range(len(row)) if pd.isnull(row[i]) == True]\n",
    "        for idx in idx_list:\n",
    "            row[idx] = row[idx - 1]\n",
    "            \n",
    "        new_df = new_df.append(pd.DataFrame(row).T, ignore_index = True)\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install -U scikit-learn scipy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7120, 491)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1 = \"./Combined_Sets_from_Revised.csv\" #\"Draft_Google_Shorter.csv\" #Removed Missing\n",
    "\n",
    "train_pd = pd.read_csv(file1)\n",
    "train_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1217, 491)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pd = train_pd[5903:]\n",
    "\n",
    "train = np.array(train_pd)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1166.569946, 2.613, ..., 4.0, 4.0, 20.0],\n",
       "       [1, 1165.790039, 2.635, ..., 4.0, 4.0, 20.0],\n",
       "       [1, 1161.660034, 2.64, ..., 4.0, 4.0, 20.0],\n",
       "       ...,\n",
       "       [4, 1697.430054, 2.512, ..., 8.0, 8.0, 46.0],\n",
       "       [4, 1706.280029, 2.501, ..., 8.0, 8.0, 46.0],\n",
       "       [4, 1707.6700440000004, 2.519, ..., 6.0, 4.0, 55.0]], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train[:,1:] # drop date\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>Label_m30</th>\n",
       "      <th>main0</th>\n",
       "      <th>main1</th>\n",
       "      <th>main2</th>\n",
       "      <th>main3</th>\n",
       "      <th>main4</th>\n",
       "      <th>main5</th>\n",
       "      <th>main6</th>\n",
       "      <th>main7</th>\n",
       "      <th>...</th>\n",
       "      <th>google_hits262</th>\n",
       "      <th>google_hits263</th>\n",
       "      <th>google_hits264</th>\n",
       "      <th>google_hits265</th>\n",
       "      <th>google_hits266</th>\n",
       "      <th>google_hits267</th>\n",
       "      <th>google_hits268</th>\n",
       "      <th>google_hits269</th>\n",
       "      <th>google_hits270</th>\n",
       "      <th>google_hits271</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5903</th>\n",
       "      <td>7/7/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1166.569946</td>\n",
       "      <td>2.613</td>\n",
       "      <td>0.158945</td>\n",
       "      <td>0.684881</td>\n",
       "      <td>0.193924</td>\n",
       "      <td>1165.790039</td>\n",
       "      <td>2.635</td>\n",
       "      <td>0.158510</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>7/8/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1165.790039</td>\n",
       "      <td>2.635</td>\n",
       "      <td>0.158510</td>\n",
       "      <td>0.684518</td>\n",
       "      <td>0.193070</td>\n",
       "      <td>1161.660034</td>\n",
       "      <td>2.640</td>\n",
       "      <td>0.157116</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5905</th>\n",
       "      <td>7/9/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1161.660034</td>\n",
       "      <td>2.640</td>\n",
       "      <td>0.157116</td>\n",
       "      <td>0.684144</td>\n",
       "      <td>0.191065</td>\n",
       "      <td>1153.599976</td>\n",
       "      <td>2.586</td>\n",
       "      <td>0.154885</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5906</th>\n",
       "      <td>7/10/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1153.599976</td>\n",
       "      <td>2.586</td>\n",
       "      <td>0.154885</td>\n",
       "      <td>0.681075</td>\n",
       "      <td>0.189443</td>\n",
       "      <td>1157.239990</td>\n",
       "      <td>2.604</td>\n",
       "      <td>0.151331</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5907</th>\n",
       "      <td>7/11/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1157.239990</td>\n",
       "      <td>2.604</td>\n",
       "      <td>0.151331</td>\n",
       "      <td>0.678147</td>\n",
       "      <td>0.184754</td>\n",
       "      <td>1158.410034</td>\n",
       "      <td>2.597</td>\n",
       "      <td>0.156583</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5908</th>\n",
       "      <td>7/14/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1158.410034</td>\n",
       "      <td>2.597</td>\n",
       "      <td>0.156583</td>\n",
       "      <td>0.669512</td>\n",
       "      <td>0.195087</td>\n",
       "      <td>1162.000000</td>\n",
       "      <td>2.655</td>\n",
       "      <td>0.157412</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5909</th>\n",
       "      <td>7/15/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1162.000000</td>\n",
       "      <td>2.655</td>\n",
       "      <td>0.157412</td>\n",
       "      <td>0.669142</td>\n",
       "      <td>0.195567</td>\n",
       "      <td>1170.449951</td>\n",
       "      <td>2.613</td>\n",
       "      <td>0.159634</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5910</th>\n",
       "      <td>7/16/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1170.449951</td>\n",
       "      <td>2.613</td>\n",
       "      <td>0.159634</td>\n",
       "      <td>0.668798</td>\n",
       "      <td>0.199618</td>\n",
       "      <td>1171.939941</td>\n",
       "      <td>2.622</td>\n",
       "      <td>0.158125</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5911</th>\n",
       "      <td>7/17/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1171.939941</td>\n",
       "      <td>2.622</td>\n",
       "      <td>0.158125</td>\n",
       "      <td>0.666257</td>\n",
       "      <td>0.197980</td>\n",
       "      <td>1174.260010</td>\n",
       "      <td>2.624</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5912</th>\n",
       "      <td>7/18/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1174.260010</td>\n",
       "      <td>2.624</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.663897</td>\n",
       "      <td>0.192207</td>\n",
       "      <td>1173.880005</td>\n",
       "      <td>2.623</td>\n",
       "      <td>0.160635</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913</th>\n",
       "      <td>7/21/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1173.880005</td>\n",
       "      <td>2.623</td>\n",
       "      <td>0.160635</td>\n",
       "      <td>0.657183</td>\n",
       "      <td>0.204516</td>\n",
       "      <td>1165.750000</td>\n",
       "      <td>2.586</td>\n",
       "      <td>0.158104</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914</th>\n",
       "      <td>7/22/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1165.750000</td>\n",
       "      <td>2.586</td>\n",
       "      <td>0.158104</td>\n",
       "      <td>0.656829</td>\n",
       "      <td>0.201336</td>\n",
       "      <td>1171.839966</td>\n",
       "      <td>2.559</td>\n",
       "      <td>0.159640</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>7/23/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1171.839966</td>\n",
       "      <td>2.559</td>\n",
       "      <td>0.159640</td>\n",
       "      <td>0.656492</td>\n",
       "      <td>0.204191</td>\n",
       "      <td>1170.410034</td>\n",
       "      <td>2.525</td>\n",
       "      <td>0.156318</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>7/24/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1170.410034</td>\n",
       "      <td>2.525</td>\n",
       "      <td>0.156318</td>\n",
       "      <td>0.654458</td>\n",
       "      <td>0.200270</td>\n",
       "      <td>1173.500000</td>\n",
       "      <td>2.532</td>\n",
       "      <td>0.152724</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5917</th>\n",
       "      <td>7/25/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1173.500000</td>\n",
       "      <td>2.532</td>\n",
       "      <td>0.152724</td>\n",
       "      <td>0.652530</td>\n",
       "      <td>0.195246</td>\n",
       "      <td>1174.069946</td>\n",
       "      <td>2.516</td>\n",
       "      <td>0.142444</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5918</th>\n",
       "      <td>7/28/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1174.069946</td>\n",
       "      <td>2.516</td>\n",
       "      <td>0.142444</td>\n",
       "      <td>0.648068</td>\n",
       "      <td>0.180975</td>\n",
       "      <td>1182.430054</td>\n",
       "      <td>2.563</td>\n",
       "      <td>0.144638</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5919</th>\n",
       "      <td>7/29/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1182.430054</td>\n",
       "      <td>2.563</td>\n",
       "      <td>0.144638</td>\n",
       "      <td>0.647642</td>\n",
       "      <td>0.183756</td>\n",
       "      <td>1181.869995</td>\n",
       "      <td>2.628</td>\n",
       "      <td>0.144288</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5920</th>\n",
       "      <td>7/30/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1181.869995</td>\n",
       "      <td>2.628</td>\n",
       "      <td>0.144288</td>\n",
       "      <td>0.647214</td>\n",
       "      <td>0.182332</td>\n",
       "      <td>1188.319946</td>\n",
       "      <td>2.648</td>\n",
       "      <td>0.145918</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5921</th>\n",
       "      <td>7/31/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1188.319946</td>\n",
       "      <td>2.648</td>\n",
       "      <td>0.145918</td>\n",
       "      <td>0.646791</td>\n",
       "      <td>0.184663</td>\n",
       "      <td>1181.420044</td>\n",
       "      <td>2.617</td>\n",
       "      <td>0.142884</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5922</th>\n",
       "      <td>8/1/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1181.420044</td>\n",
       "      <td>2.617</td>\n",
       "      <td>0.142884</td>\n",
       "      <td>0.642908</td>\n",
       "      <td>0.181541</td>\n",
       "      <td>1172.030029</td>\n",
       "      <td>2.565</td>\n",
       "      <td>0.140034</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5923</th>\n",
       "      <td>8/4/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1172.030029</td>\n",
       "      <td>2.565</td>\n",
       "      <td>0.140034</td>\n",
       "      <td>0.642481</td>\n",
       "      <td>0.178035</td>\n",
       "      <td>1177.130005</td>\n",
       "      <td>2.547</td>\n",
       "      <td>0.141303</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5924</th>\n",
       "      <td>8/5/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1177.130005</td>\n",
       "      <td>2.547</td>\n",
       "      <td>0.141303</td>\n",
       "      <td>0.642055</td>\n",
       "      <td>0.180410</td>\n",
       "      <td>1171.760010</td>\n",
       "      <td>2.532</td>\n",
       "      <td>0.146189</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5925</th>\n",
       "      <td>8/6/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1171.760010</td>\n",
       "      <td>2.532</td>\n",
       "      <td>0.146189</td>\n",
       "      <td>0.640781</td>\n",
       "      <td>0.188627</td>\n",
       "      <td>1172.939941</td>\n",
       "      <td>2.520</td>\n",
       "      <td>0.148014</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5926</th>\n",
       "      <td>8/7/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1172.939941</td>\n",
       "      <td>2.520</td>\n",
       "      <td>0.148014</td>\n",
       "      <td>0.639452</td>\n",
       "      <td>0.192061</td>\n",
       "      <td>1178.569946</td>\n",
       "      <td>2.549</td>\n",
       "      <td>0.149452</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5927</th>\n",
       "      <td>8/8/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1178.569946</td>\n",
       "      <td>2.549</td>\n",
       "      <td>0.149452</td>\n",
       "      <td>0.636357</td>\n",
       "      <td>0.194799</td>\n",
       "      <td>1175.109985</td>\n",
       "      <td>2.549</td>\n",
       "      <td>0.148271</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5928</th>\n",
       "      <td>8/11/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1175.109985</td>\n",
       "      <td>2.549</td>\n",
       "      <td>0.148271</td>\n",
       "      <td>0.635947</td>\n",
       "      <td>0.193068</td>\n",
       "      <td>1178.989990</td>\n",
       "      <td>2.538</td>\n",
       "      <td>0.149178</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5929</th>\n",
       "      <td>8/12/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1178.989990</td>\n",
       "      <td>2.538</td>\n",
       "      <td>0.149178</td>\n",
       "      <td>0.635542</td>\n",
       "      <td>0.194791</td>\n",
       "      <td>1164.849976</td>\n",
       "      <td>2.475</td>\n",
       "      <td>0.148322</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5930</th>\n",
       "      <td>8/13/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1164.849976</td>\n",
       "      <td>2.475</td>\n",
       "      <td>0.148322</td>\n",
       "      <td>0.633860</td>\n",
       "      <td>0.194951</td>\n",
       "      <td>1177.619995</td>\n",
       "      <td>2.484</td>\n",
       "      <td>0.146260</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5931</th>\n",
       "      <td>8/14/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1177.619995</td>\n",
       "      <td>2.484</td>\n",
       "      <td>0.146260</td>\n",
       "      <td>0.632399</td>\n",
       "      <td>0.191999</td>\n",
       "      <td>1174.709961</td>\n",
       "      <td>2.474</td>\n",
       "      <td>0.141372</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>8/15/14</td>\n",
       "      <td>1</td>\n",
       "      <td>1174.709961</td>\n",
       "      <td>2.474</td>\n",
       "      <td>0.141372</td>\n",
       "      <td>0.628778</td>\n",
       "      <td>0.185491</td>\n",
       "      <td>1180.989990</td>\n",
       "      <td>2.466</td>\n",
       "      <td>0.142974</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7090</th>\n",
       "      <td>3/25/19</td>\n",
       "      <td>1</td>\n",
       "      <td>1656.439941</td>\n",
       "      <td>2.636</td>\n",
       "      <td>0.131973</td>\n",
       "      <td>0.243117</td>\n",
       "      <td>0.434414</td>\n",
       "      <td>1654.160034</td>\n",
       "      <td>2.693</td>\n",
       "      <td>0.131339</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7091</th>\n",
       "      <td>3/26/19</td>\n",
       "      <td>0</td>\n",
       "      <td>1654.160034</td>\n",
       "      <td>2.693</td>\n",
       "      <td>0.131339</td>\n",
       "      <td>0.243814</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>1649.219971</td>\n",
       "      <td>2.711</td>\n",
       "      <td>0.132760</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7092</th>\n",
       "      <td>3/27/19</td>\n",
       "      <td>0</td>\n",
       "      <td>1649.219971</td>\n",
       "      <td>2.711</td>\n",
       "      <td>0.132760</td>\n",
       "      <td>0.244727</td>\n",
       "      <td>0.431705</td>\n",
       "      <td>1660.609985</td>\n",
       "      <td>2.755</td>\n",
       "      <td>0.127271</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7093</th>\n",
       "      <td>3/28/19</td>\n",
       "      <td>1</td>\n",
       "      <td>1660.609985</td>\n",
       "      <td>2.755</td>\n",
       "      <td>0.127271</td>\n",
       "      <td>0.245346</td>\n",
       "      <td>0.406450</td>\n",
       "      <td>1660.609985</td>\n",
       "      <td>2.722</td>\n",
       "      <td>0.123074</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7094</th>\n",
       "      <td>3/29/19</td>\n",
       "      <td>1</td>\n",
       "      <td>1660.609985</td>\n",
       "      <td>2.722</td>\n",
       "      <td>0.123074</td>\n",
       "      <td>0.246080</td>\n",
       "      <td>0.389523</td>\n",
       "      <td>1650.260010</td>\n",
       "      <td>2.722</td>\n",
       "      <td>0.120828</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7095</th>\n",
       "      <td>4/1/19</td>\n",
       "      <td>1</td>\n",
       "      <td>1650.260010</td>\n",
       "      <td>2.722</td>\n",
       "      <td>0.120828</td>\n",
       "      <td>0.246323</td>\n",
       "      <td>0.380020</td>\n",
       "      <td>1650.260010</td>\n",
       "      <td>2.692</td>\n",
       "      <td>0.120668</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7096</th>\n",
       "      <td>4/2/19</td>\n",
       "      <td>0</td>\n",
       "      <td>1650.260010</td>\n",
       "      <td>2.692</td>\n",
       "      <td>0.120668</td>\n",
       "      <td>0.246568</td>\n",
       "      <td>0.380210</td>\n",
       "      <td>1624.060059</td>\n",
       "      <td>2.636</td>\n",
       "      <td>0.114679</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7097</th>\n",
       "      <td>4/3/19</td>\n",
       "      <td>1</td>\n",
       "      <td>1624.060059</td>\n",
       "      <td>2.636</td>\n",
       "      <td>0.114679</td>\n",
       "      <td>0.246812</td>\n",
       "      <td>0.357838</td>\n",
       "      <td>1620.699951</td>\n",
       "      <td>2.625</td>\n",
       "      <td>0.118365</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>4/4/19</td>\n",
       "      <td>1</td>\n",
       "      <td>1620.699951</td>\n",
       "      <td>2.625</td>\n",
       "      <td>0.118365</td>\n",
       "      <td>0.247164</td>\n",
       "      <td>0.372688</td>\n",
       "      <td>1644.869995</td>\n",
       "      <td>2.643</td>\n",
       "      <td>0.116500</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7099</th>\n",
       "      <td>4/5/19</td>\n",
       "      <td>0</td>\n",
       "      <td>1644.869995</td>\n",
       "      <td>2.643</td>\n",
       "      <td>0.116500</td>\n",
       "      <td>0.247770</td>\n",
       "      <td>0.363524</td>\n",
       "      <td>1649.469971</td>\n",
       "      <td>2.605</td>\n",
       "      <td>0.117281</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>4/8/19</td>\n",
       "      <td>4</td>\n",
       "      <td>1649.469971</td>\n",
       "      <td>2.605</td>\n",
       "      <td>0.117281</td>\n",
       "      <td>0.247930</td>\n",
       "      <td>0.367968</td>\n",
       "      <td>1660.250000</td>\n",
       "      <td>2.611</td>\n",
       "      <td>0.119307</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7101</th>\n",
       "      <td>4/9/19</td>\n",
       "      <td>4</td>\n",
       "      <td>1660.250000</td>\n",
       "      <td>2.611</td>\n",
       "      <td>0.119307</td>\n",
       "      <td>0.248149</td>\n",
       "      <td>0.375566</td>\n",
       "      <td>1658.359985</td>\n",
       "      <td>2.630</td>\n",
       "      <td>0.119449</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7102</th>\n",
       "      <td>4/10/19</td>\n",
       "      <td>4</td>\n",
       "      <td>1658.359985</td>\n",
       "      <td>2.630</td>\n",
       "      <td>0.119449</td>\n",
       "      <td>0.248528</td>\n",
       "      <td>0.374804</td>\n",
       "      <td>1665.839966</td>\n",
       "      <td>2.593</td>\n",
       "      <td>0.122162</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7103</th>\n",
       "      <td>4/11/19</td>\n",
       "      <td>4</td>\n",
       "      <td>1665.839966</td>\n",
       "      <td>2.593</td>\n",
       "      <td>0.122162</td>\n",
       "      <td>0.249011</td>\n",
       "      <td>0.386457</td>\n",
       "      <td>1672.589966</td>\n",
       "      <td>2.602</td>\n",
       "      <td>0.117594</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7104</th>\n",
       "      <td>4/12/19</td>\n",
       "      <td>4</td>\n",
       "      <td>1672.589966</td>\n",
       "      <td>2.602</td>\n",
       "      <td>0.117594</td>\n",
       "      <td>0.249571</td>\n",
       "      <td>0.366925</td>\n",
       "      <td>1671.180054</td>\n",
       "      <td>2.614</td>\n",
       "      <td>0.117156</td>\n",
       "      <td>...</td>\n",
       "      <td>32.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7105</th>\n",
       "      <td>4/15/19</td>\n",
       "      <td>4</td>\n",
       "      <td>1671.180054</td>\n",
       "      <td>2.614</td>\n",
       "      <td>0.117156</td>\n",
       "      <td>0.249717</td>\n",
       "      <td>0.364477</td>\n",
       "      <td>1665.250000</td>\n",
       "      <td>2.535</td>\n",
       "      <td>0.115816</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7106</th>\n",
       "      <td>4/16/19</td>\n",
       "      <td>4</td>\n",
       "      <td>1665.250000</td>\n",
       "      <td>2.535</td>\n",
       "      <td>0.115816</td>\n",
       "      <td>0.249846</td>\n",
       "      <td>0.362088</td>\n",
       "      <td>1665.250000</td>\n",
       "      <td>2.537</td>\n",
       "      <td>0.115547</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7107</th>\n",
       "      <td>4/17/19</td>\n",
       "      <td>4</td>\n",
       "      <td>1665.250000</td>\n",
       "      <td>2.537</td>\n",
       "      <td>0.115547</td>\n",
       "      <td>0.250090</td>\n",
       "      <td>0.360580</td>\n",
       "      <td>1649.050049</td>\n",
       "      <td>2.455</td>\n",
       "      <td>0.112511</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7108</th>\n",
       "      <td>4/18/19</td>\n",
       "      <td>4</td>\n",
       "      <td>1649.050049</td>\n",
       "      <td>2.455</td>\n",
       "      <td>0.112511</td>\n",
       "      <td>0.250281</td>\n",
       "      <td>0.351449</td>\n",
       "      <td>1649.050049</td>\n",
       "      <td>2.420</td>\n",
       "      <td>0.115375</td>\n",
       "      <td>...</td>\n",
       "      <td>59.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7109</th>\n",
       "      <td>4/22/19</td>\n",
       "      <td>4</td>\n",
       "      <td>1649.050049</td>\n",
       "      <td>2.420</td>\n",
       "      <td>0.115375</td>\n",
       "      <td>0.250718</td>\n",
       "      <td>0.363655</td>\n",
       "      <td>1660.599976</td>\n",
       "      <td>2.414</td>\n",
       "      <td>0.117560</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7110</th>\n",
       "      <td>4/23/19</td>\n",
       "      <td>4</td>\n",
       "      <td>1660.599976</td>\n",
       "      <td>2.414</td>\n",
       "      <td>0.117560</td>\n",
       "      <td>0.250931</td>\n",
       "      <td>0.372292</td>\n",
       "      <td>1660.599976</td>\n",
       "      <td>2.374</td>\n",
       "      <td>0.117404</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7111</th>\n",
       "      <td>4/24/19</td>\n",
       "      <td>4</td>\n",
       "      <td>1660.599976</td>\n",
       "      <td>2.374</td>\n",
       "      <td>0.117404</td>\n",
       "      <td>0.251151</td>\n",
       "      <td>0.372940</td>\n",
       "      <td>1660.030029</td>\n",
       "      <td>2.389</td>\n",
       "      <td>0.117083</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7112</th>\n",
       "      <td>4/25/19</td>\n",
       "      <td>4</td>\n",
       "      <td>1660.030029</td>\n",
       "      <td>2.389</td>\n",
       "      <td>0.117083</td>\n",
       "      <td>0.251515</td>\n",
       "      <td>0.370528</td>\n",
       "      <td>1660.030029</td>\n",
       "      <td>2.414</td>\n",
       "      <td>0.113530</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7113</th>\n",
       "      <td>4/26/19</td>\n",
       "      <td>4</td>\n",
       "      <td>1660.030029</td>\n",
       "      <td>2.414</td>\n",
       "      <td>0.113530</td>\n",
       "      <td>0.251742</td>\n",
       "      <td>0.355084</td>\n",
       "      <td>1690.180054</td>\n",
       "      <td>2.497</td>\n",
       "      <td>0.116988</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7114</th>\n",
       "      <td>4/29/19</td>\n",
       "      <td>4</td>\n",
       "      <td>1690.180054</td>\n",
       "      <td>2.497</td>\n",
       "      <td>0.116988</td>\n",
       "      <td>0.252228</td>\n",
       "      <td>0.364822</td>\n",
       "      <td>1689.890015</td>\n",
       "      <td>2.481</td>\n",
       "      <td>0.116776</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7115</th>\n",
       "      <td>4/30/19</td>\n",
       "      <td>4</td>\n",
       "      <td>1689.890015</td>\n",
       "      <td>2.481</td>\n",
       "      <td>0.116776</td>\n",
       "      <td>0.252391</td>\n",
       "      <td>0.364379</td>\n",
       "      <td>1694.329956</td>\n",
       "      <td>2.517</td>\n",
       "      <td>0.117497</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7116</th>\n",
       "      <td>5/1/19</td>\n",
       "      <td>4</td>\n",
       "      <td>1694.329956</td>\n",
       "      <td>2.517</td>\n",
       "      <td>0.117497</td>\n",
       "      <td>0.252563</td>\n",
       "      <td>0.365562</td>\n",
       "      <td>1697.430054</td>\n",
       "      <td>2.512</td>\n",
       "      <td>0.119412</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7117</th>\n",
       "      <td>5/2/19</td>\n",
       "      <td>4</td>\n",
       "      <td>1697.430054</td>\n",
       "      <td>2.512</td>\n",
       "      <td>0.119412</td>\n",
       "      <td>0.252846</td>\n",
       "      <td>0.372924</td>\n",
       "      <td>1706.280029</td>\n",
       "      <td>2.501</td>\n",
       "      <td>0.124507</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7118</th>\n",
       "      <td>5/3/19</td>\n",
       "      <td>4</td>\n",
       "      <td>1706.280029</td>\n",
       "      <td>2.501</td>\n",
       "      <td>0.124507</td>\n",
       "      <td>0.253361</td>\n",
       "      <td>0.392709</td>\n",
       "      <td>1707.670044</td>\n",
       "      <td>2.519</td>\n",
       "      <td>0.124547</td>\n",
       "      <td>...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7119</th>\n",
       "      <td>5/6/19</td>\n",
       "      <td>4</td>\n",
       "      <td>1707.670044</td>\n",
       "      <td>2.519</td>\n",
       "      <td>0.124547</td>\n",
       "      <td>0.254077</td>\n",
       "      <td>0.391049</td>\n",
       "      <td>1707.670044</td>\n",
       "      <td>2.499</td>\n",
       "      <td>0.124382</td>\n",
       "      <td>...</td>\n",
       "      <td>93.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1217 rows × 491 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dates  Label_m30        main0  main1     main2     main3     main4  \\\n",
       "5903   7/7/14          1  1166.569946  2.613  0.158945  0.684881  0.193924   \n",
       "5904   7/8/14          1  1165.790039  2.635  0.158510  0.684518  0.193070   \n",
       "5905   7/9/14          1  1161.660034  2.640  0.157116  0.684144  0.191065   \n",
       "5906  7/10/14          1  1153.599976  2.586  0.154885  0.681075  0.189443   \n",
       "5907  7/11/14          1  1157.239990  2.604  0.151331  0.678147  0.184754   \n",
       "5908  7/14/14          1  1158.410034  2.597  0.156583  0.669512  0.195087   \n",
       "5909  7/15/14          1  1162.000000  2.655  0.157412  0.669142  0.195567   \n",
       "5910  7/16/14          1  1170.449951  2.613  0.159634  0.668798  0.199618   \n",
       "5911  7/17/14          1  1171.939941  2.622  0.158125  0.666257  0.197980   \n",
       "5912  7/18/14          1  1174.260010  2.624  0.153846  0.663897  0.192207   \n",
       "5913  7/21/14          1  1173.880005  2.623  0.160635  0.657183  0.204516   \n",
       "5914  7/22/14          1  1165.750000  2.586  0.158104  0.656829  0.201336   \n",
       "5915  7/23/14          1  1171.839966  2.559  0.159640  0.656492  0.204191   \n",
       "5916  7/24/14          1  1170.410034  2.525  0.156318  0.654458  0.200270   \n",
       "5917  7/25/14          1  1173.500000  2.532  0.152724  0.652530  0.195246   \n",
       "5918  7/28/14          1  1174.069946  2.516  0.142444  0.648068  0.180975   \n",
       "5919  7/29/14          1  1182.430054  2.563  0.144638  0.647642  0.183756   \n",
       "5920  7/30/14          1  1181.869995  2.628  0.144288  0.647214  0.182332   \n",
       "5921  7/31/14          1  1188.319946  2.648  0.145918  0.646791  0.184663   \n",
       "5922   8/1/14          1  1181.420044  2.617  0.142884  0.642908  0.181541   \n",
       "5923   8/4/14          1  1172.030029  2.565  0.140034  0.642481  0.178035   \n",
       "5924   8/5/14          1  1177.130005  2.547  0.141303  0.642055  0.180410   \n",
       "5925   8/6/14          1  1171.760010  2.532  0.146189  0.640781  0.188627   \n",
       "5926   8/7/14          1  1172.939941  2.520  0.148014  0.639452  0.192061   \n",
       "5927   8/8/14          1  1178.569946  2.549  0.149452  0.636357  0.194799   \n",
       "5928  8/11/14          1  1175.109985  2.549  0.148271  0.635947  0.193068   \n",
       "5929  8/12/14          1  1178.989990  2.538  0.149178  0.635542  0.194791   \n",
       "5930  8/13/14          1  1164.849976  2.475  0.148322  0.633860  0.194951   \n",
       "5931  8/14/14          1  1177.619995  2.484  0.146260  0.632399  0.191999   \n",
       "5932  8/15/14          1  1174.709961  2.474  0.141372  0.628778  0.185491   \n",
       "...       ...        ...          ...    ...       ...       ...       ...   \n",
       "7090  3/25/19          1  1656.439941  2.636  0.131973  0.243117  0.434414   \n",
       "7091  3/26/19          0  1654.160034  2.693  0.131339  0.243814  0.428232   \n",
       "7092  3/27/19          0  1649.219971  2.711  0.132760  0.244727  0.431705   \n",
       "7093  3/28/19          1  1660.609985  2.755  0.127271  0.245346  0.406450   \n",
       "7094  3/29/19          1  1660.609985  2.722  0.123074  0.246080  0.389523   \n",
       "7095   4/1/19          1  1650.260010  2.722  0.120828  0.246323  0.380020   \n",
       "7096   4/2/19          0  1650.260010  2.692  0.120668  0.246568  0.380210   \n",
       "7097   4/3/19          1  1624.060059  2.636  0.114679  0.246812  0.357838   \n",
       "7098   4/4/19          1  1620.699951  2.625  0.118365  0.247164  0.372688   \n",
       "7099   4/5/19          0  1644.869995  2.643  0.116500  0.247770  0.363524   \n",
       "7100   4/8/19          4  1649.469971  2.605  0.117281  0.247930  0.367968   \n",
       "7101   4/9/19          4  1660.250000  2.611  0.119307  0.248149  0.375566   \n",
       "7102  4/10/19          4  1658.359985  2.630  0.119449  0.248528  0.374804   \n",
       "7103  4/11/19          4  1665.839966  2.593  0.122162  0.249011  0.386457   \n",
       "7104  4/12/19          4  1672.589966  2.602  0.117594  0.249571  0.366925   \n",
       "7105  4/15/19          4  1671.180054  2.614  0.117156  0.249717  0.364477   \n",
       "7106  4/16/19          4  1665.250000  2.535  0.115816  0.249846  0.362088   \n",
       "7107  4/17/19          4  1665.250000  2.537  0.115547  0.250090  0.360580   \n",
       "7108  4/18/19          4  1649.050049  2.455  0.112511  0.250281  0.351449   \n",
       "7109  4/22/19          4  1649.050049  2.420  0.115375  0.250718  0.363655   \n",
       "7110  4/23/19          4  1660.599976  2.414  0.117560  0.250931  0.372292   \n",
       "7111  4/24/19          4  1660.599976  2.374  0.117404  0.251151  0.372940   \n",
       "7112  4/25/19          4  1660.030029  2.389  0.117083  0.251515  0.370528   \n",
       "7113  4/26/19          4  1660.030029  2.414  0.113530  0.251742  0.355084   \n",
       "7114  4/29/19          4  1690.180054  2.497  0.116988  0.252228  0.364822   \n",
       "7115  4/30/19          4  1689.890015  2.481  0.116776  0.252391  0.364379   \n",
       "7116   5/1/19          4  1694.329956  2.517  0.117497  0.252563  0.365562   \n",
       "7117   5/2/19          4  1697.430054  2.512  0.119412  0.252846  0.372924   \n",
       "7118   5/3/19          4  1706.280029  2.501  0.124507  0.253361  0.392709   \n",
       "7119   5/6/19          4  1707.670044  2.519  0.124547  0.254077  0.391049   \n",
       "\n",
       "            main5  main6     main7       ...        google_hits262  \\\n",
       "5903  1165.790039  2.635  0.158510       ...                  14.0   \n",
       "5904  1161.660034  2.640  0.157116       ...                  14.0   \n",
       "5905  1153.599976  2.586  0.154885       ...                  14.0   \n",
       "5906  1157.239990  2.604  0.151331       ...                  14.0   \n",
       "5907  1158.410034  2.597  0.156583       ...                  14.0   \n",
       "5908  1162.000000  2.655  0.157412       ...                   6.0   \n",
       "5909  1170.449951  2.613  0.159634       ...                   6.0   \n",
       "5910  1171.939941  2.622  0.158125       ...                   6.0   \n",
       "5911  1174.260010  2.624  0.153846       ...                   6.0   \n",
       "5912  1173.880005  2.623  0.160635       ...                   6.0   \n",
       "5913  1165.750000  2.586  0.158104       ...                  11.0   \n",
       "5914  1171.839966  2.559  0.159640       ...                  11.0   \n",
       "5915  1170.410034  2.525  0.156318       ...                  11.0   \n",
       "5916  1173.500000  2.532  0.152724       ...                  11.0   \n",
       "5917  1174.069946  2.516  0.142444       ...                  11.0   \n",
       "5918  1182.430054  2.563  0.144638       ...                  17.0   \n",
       "5919  1181.869995  2.628  0.144288       ...                  17.0   \n",
       "5920  1188.319946  2.648  0.145918       ...                  17.0   \n",
       "5921  1181.420044  2.617  0.142884       ...                  17.0   \n",
       "5922  1172.030029  2.565  0.140034       ...                  17.0   \n",
       "5923  1177.130005  2.547  0.141303       ...                  21.0   \n",
       "5924  1171.760010  2.532  0.146189       ...                  21.0   \n",
       "5925  1172.939941  2.520  0.148014       ...                  21.0   \n",
       "5926  1178.569946  2.549  0.149452       ...                  21.0   \n",
       "5927  1175.109985  2.549  0.148271       ...                  21.0   \n",
       "5928  1178.989990  2.538  0.149178       ...                  14.0   \n",
       "5929  1164.849976  2.475  0.148322       ...                  14.0   \n",
       "5930  1177.619995  2.484  0.146260       ...                  14.0   \n",
       "5931  1174.709961  2.474  0.141372       ...                  14.0   \n",
       "5932  1180.989990  2.466  0.142974       ...                  14.0   \n",
       "...           ...    ...       ...       ...                   ...   \n",
       "7090  1654.160034  2.693  0.131339       ...                  54.0   \n",
       "7091  1649.219971  2.711  0.132760       ...                  54.0   \n",
       "7092  1660.609985  2.755  0.127271       ...                  54.0   \n",
       "7093  1660.609985  2.722  0.123074       ...                  54.0   \n",
       "7094  1650.260010  2.722  0.120828       ...                  54.0   \n",
       "7095  1650.260010  2.692  0.120668       ...                  54.0   \n",
       "7096  1624.060059  2.636  0.114679       ...                  54.0   \n",
       "7097  1620.699951  2.625  0.118365       ...                  54.0   \n",
       "7098  1644.869995  2.643  0.116500       ...                  54.0   \n",
       "7099  1649.469971  2.605  0.117281       ...                  54.0   \n",
       "7100  1660.250000  2.611  0.119307       ...                  32.0   \n",
       "7101  1658.359985  2.630  0.119449       ...                  32.0   \n",
       "7102  1665.839966  2.593  0.122162       ...                  32.0   \n",
       "7103  1672.589966  2.602  0.117594       ...                  32.0   \n",
       "7104  1671.180054  2.614  0.117156       ...                  32.0   \n",
       "7105  1665.250000  2.535  0.115816       ...                  59.0   \n",
       "7106  1665.250000  2.537  0.115547       ...                  59.0   \n",
       "7107  1649.050049  2.455  0.112511       ...                  59.0   \n",
       "7108  1649.050049  2.420  0.115375       ...                  59.0   \n",
       "7109  1660.599976  2.414  0.117560       ...                  64.0   \n",
       "7110  1660.599976  2.374  0.117404       ...                  64.0   \n",
       "7111  1660.030029  2.389  0.117083       ...                  64.0   \n",
       "7112  1660.030029  2.414  0.113530       ...                  64.0   \n",
       "7113  1690.180054  2.497  0.116988       ...                  64.0   \n",
       "7114  1689.890015  2.481  0.116776       ...                  41.0   \n",
       "7115  1694.329956  2.517  0.117497       ...                  41.0   \n",
       "7116  1697.430054  2.512  0.119412       ...                  41.0   \n",
       "7117  1706.280029  2.501  0.124507       ...                  41.0   \n",
       "7118  1707.670044  2.519  0.124547       ...                  41.0   \n",
       "7119  1707.670044  2.499  0.124382       ...                  93.0   \n",
       "\n",
       "      google_hits263  google_hits264  google_hits265  google_hits266  \\\n",
       "5903            19.0            10.0            11.0            19.0   \n",
       "5904            19.0            10.0            11.0            19.0   \n",
       "5905            19.0            10.0            11.0            19.0   \n",
       "5906            19.0            10.0            11.0            19.0   \n",
       "5907            19.0            10.0            11.0            19.0   \n",
       "5908            11.0            39.0             9.0            23.0   \n",
       "5909            11.0            39.0             9.0            23.0   \n",
       "5910            11.0            39.0             9.0            23.0   \n",
       "5911            11.0            39.0             9.0            23.0   \n",
       "5912            11.0            39.0             9.0            23.0   \n",
       "5913            22.0           100.0            11.0            18.0   \n",
       "5914            22.0           100.0            11.0            18.0   \n",
       "5915            22.0           100.0            11.0            18.0   \n",
       "5916            22.0           100.0            11.0            18.0   \n",
       "5917            22.0           100.0            11.0            18.0   \n",
       "5918            13.0            12.0            20.0            18.0   \n",
       "5919            13.0            12.0            20.0            18.0   \n",
       "5920            13.0            12.0            20.0            18.0   \n",
       "5921            13.0            12.0            20.0            18.0   \n",
       "5922            13.0            12.0            20.0            18.0   \n",
       "5923             5.0            11.0            17.0            16.0   \n",
       "5924             5.0            11.0            17.0            16.0   \n",
       "5925             5.0            11.0            17.0            16.0   \n",
       "5926             5.0            11.0            17.0            16.0   \n",
       "5927             5.0            11.0            17.0            16.0   \n",
       "5928            14.0            15.0            13.0            12.0   \n",
       "5929            14.0            15.0            13.0            12.0   \n",
       "5930            14.0            15.0            13.0            12.0   \n",
       "5931            14.0            15.0            13.0            12.0   \n",
       "5932            14.0            15.0            13.0            12.0   \n",
       "...              ...             ...             ...             ...   \n",
       "7090            22.0            15.0            25.0            19.0   \n",
       "7091            22.0            15.0            25.0            19.0   \n",
       "7092            22.0            15.0            25.0            19.0   \n",
       "7093            22.0            15.0            25.0            19.0   \n",
       "7094            22.0            15.0            25.0            19.0   \n",
       "7095            32.0            10.0            36.0            25.0   \n",
       "7096            32.0            10.0            36.0            25.0   \n",
       "7097            32.0            10.0            36.0            25.0   \n",
       "7098            32.0            10.0            36.0            25.0   \n",
       "7099            32.0            10.0            36.0            25.0   \n",
       "7100            28.0            25.0            36.0            25.0   \n",
       "7101            28.0            25.0            36.0            25.0   \n",
       "7102            28.0            25.0            36.0            25.0   \n",
       "7103            28.0            25.0            36.0            25.0   \n",
       "7104            28.0            25.0            36.0            25.0   \n",
       "7105            27.0            11.0            32.0            18.0   \n",
       "7106            27.0            11.0            32.0            18.0   \n",
       "7107            27.0            11.0            32.0            18.0   \n",
       "7108            27.0            11.0            32.0            18.0   \n",
       "7109            37.0            17.0            20.0            17.0   \n",
       "7110            37.0            17.0            20.0            17.0   \n",
       "7111            37.0            17.0            20.0            17.0   \n",
       "7112            37.0            17.0            20.0            17.0   \n",
       "7113            37.0            17.0            20.0            17.0   \n",
       "7114            14.0            18.0            22.0            21.0   \n",
       "7115            14.0            18.0            22.0            21.0   \n",
       "7116            14.0            18.0            22.0            21.0   \n",
       "7117            14.0            18.0            22.0            21.0   \n",
       "7118            14.0            18.0            22.0            21.0   \n",
       "7119             9.0            18.0            31.0            10.0   \n",
       "\n",
       "      google_hits267  google_hits268  google_hits269  google_hits270  \\\n",
       "5903            22.0             0.0             4.0             4.0   \n",
       "5904            22.0             0.0             4.0             4.0   \n",
       "5905            22.0             0.0             4.0             4.0   \n",
       "5906            22.0             0.0             4.0             4.0   \n",
       "5907            22.0             0.0             4.0             4.0   \n",
       "5908            15.0             3.0             4.0             6.0   \n",
       "5909            15.0             3.0             4.0             6.0   \n",
       "5910            15.0             3.0             4.0             6.0   \n",
       "5911            15.0             3.0             4.0             6.0   \n",
       "5912            15.0             3.0             4.0             6.0   \n",
       "5913            19.0             3.0             2.0             6.0   \n",
       "5914            19.0             3.0             2.0             6.0   \n",
       "5915            19.0             3.0             2.0             6.0   \n",
       "5916            19.0             3.0             2.0             6.0   \n",
       "5917            19.0             3.0             2.0             6.0   \n",
       "5918            20.0             1.0             4.0             2.0   \n",
       "5919            20.0             1.0             4.0             2.0   \n",
       "5920            20.0             1.0             4.0             2.0   \n",
       "5921            20.0             1.0             4.0             2.0   \n",
       "5922            20.0             1.0             4.0             2.0   \n",
       "5923            27.0             0.0             3.0             4.0   \n",
       "5924            27.0             0.0             3.0             4.0   \n",
       "5925            27.0             0.0             3.0             4.0   \n",
       "5926            27.0             0.0             3.0             4.0   \n",
       "5927            27.0             0.0             3.0             4.0   \n",
       "5928            16.0             0.0             5.0             5.0   \n",
       "5929            16.0             0.0             5.0             5.0   \n",
       "5930            16.0             0.0             5.0             5.0   \n",
       "5931            16.0             0.0             5.0             5.0   \n",
       "5932            16.0             0.0             5.0             5.0   \n",
       "...              ...             ...             ...             ...   \n",
       "7090            22.0             0.0            10.0             4.0   \n",
       "7091            22.0             0.0            10.0             4.0   \n",
       "7092            22.0             0.0            10.0             4.0   \n",
       "7093            22.0             0.0            10.0             4.0   \n",
       "7094            22.0             0.0            10.0             4.0   \n",
       "7095            19.0             5.0            16.0             4.0   \n",
       "7096            19.0             5.0            16.0             4.0   \n",
       "7097            19.0             5.0            16.0             4.0   \n",
       "7098            19.0             5.0            16.0             4.0   \n",
       "7099            19.0             5.0            16.0             4.0   \n",
       "7100            48.0             0.0             8.0             0.0   \n",
       "7101            48.0             0.0             8.0             0.0   \n",
       "7102            48.0             0.0             8.0             0.0   \n",
       "7103            48.0             0.0             8.0             0.0   \n",
       "7104            48.0             0.0             8.0             0.0   \n",
       "7105            26.0             4.0            10.0             0.0   \n",
       "7106            26.0             4.0            10.0             0.0   \n",
       "7107            26.0             4.0            10.0             0.0   \n",
       "7108            26.0             4.0            10.0             0.0   \n",
       "7109            36.0             6.0             8.0             0.0   \n",
       "7110            36.0             6.0             8.0             0.0   \n",
       "7111            36.0             6.0             8.0             0.0   \n",
       "7112            36.0             6.0             8.0             0.0   \n",
       "7113            36.0             6.0             8.0             0.0   \n",
       "7114            36.0             0.0             8.0             8.0   \n",
       "7115            36.0             0.0             8.0             8.0   \n",
       "7116            36.0             0.0             8.0             8.0   \n",
       "7117            36.0             0.0             8.0             8.0   \n",
       "7118            36.0             0.0             8.0             8.0   \n",
       "7119            38.0             3.0             6.0             4.0   \n",
       "\n",
       "      google_hits271  \n",
       "5903            20.0  \n",
       "5904            20.0  \n",
       "5905            20.0  \n",
       "5906            20.0  \n",
       "5907            20.0  \n",
       "5908            14.0  \n",
       "5909            14.0  \n",
       "5910            14.0  \n",
       "5911            14.0  \n",
       "5912            14.0  \n",
       "5913            16.0  \n",
       "5914            16.0  \n",
       "5915            16.0  \n",
       "5916            16.0  \n",
       "5917            16.0  \n",
       "5918            20.0  \n",
       "5919            20.0  \n",
       "5920            20.0  \n",
       "5921            20.0  \n",
       "5922            20.0  \n",
       "5923            11.0  \n",
       "5924            11.0  \n",
       "5925            11.0  \n",
       "5926            11.0  \n",
       "5927            11.0  \n",
       "5928            14.0  \n",
       "5929            14.0  \n",
       "5930            14.0  \n",
       "5931            14.0  \n",
       "5932            14.0  \n",
       "...              ...  \n",
       "7090            24.0  \n",
       "7091            24.0  \n",
       "7092            24.0  \n",
       "7093            24.0  \n",
       "7094            24.0  \n",
       "7095            52.0  \n",
       "7096            52.0  \n",
       "7097            52.0  \n",
       "7098            52.0  \n",
       "7099            52.0  \n",
       "7100            51.0  \n",
       "7101            51.0  \n",
       "7102            51.0  \n",
       "7103            51.0  \n",
       "7104            51.0  \n",
       "7105            46.0  \n",
       "7106            46.0  \n",
       "7107            46.0  \n",
       "7108            46.0  \n",
       "7109            28.0  \n",
       "7110            28.0  \n",
       "7111            28.0  \n",
       "7112            28.0  \n",
       "7113            28.0  \n",
       "7114            46.0  \n",
       "7115            46.0  \n",
       "7116            46.0  \n",
       "7117            46.0  \n",
       "7118            46.0  \n",
       "7119            55.0  \n",
       "\n",
       "[1217 rows x 491 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Time-Series Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_cross(array, time_shift = 0, size_train_set = 365, size_val_set = 100, set_shift = 0):\n",
    "    np.random.seed(100)\n",
    "    label_idx = 0\n",
    "\n",
    "    if time_shift == 0:\n",
    "        time_shift = size_train_set + size_val_set + set_shift\n",
    "        \n",
    "    train_size = train.shape\n",
    "    j = 0\n",
    "    group = 1\n",
    "    end = train_size[0]\n",
    "    trainDataPartition = [] # list\n",
    "    valDataPartition = []\n",
    "\n",
    "    #print(size_train_set, size_val_set, train_size[0])\n",
    "    while j + (size_train_set + size_val_set + set_shift) < train_size[0]:\n",
    "        trainset = []\n",
    "        valset = []\n",
    "\n",
    "        trainset = train[j:j+size_train_set, :] # array\n",
    "        valset = train[j+size_train_set+1+set_shift:j+size_train_set+size_val_set+set_shift, :]\n",
    "\n",
    "        trainDataPartition.append(trainset)\n",
    "        valDataPartition.append(valset)\n",
    "    \n",
    "        group = group+1;\n",
    "        j = j + time_shift\n",
    "\n",
    "\n",
    "    # make last set -- decide if you want to throw out or adjust this set\n",
    "    trainset = train[j:j+size_train_set, :]\n",
    "    valset = train[j+size_train_set+1+set_shift:end, :]\n",
    "    \n",
    "    trainDataPartition.append(trainset)\n",
    "    valDataPartition.append(valset)\n",
    "\n",
    "    \n",
    "    ### Optional: stratify\n",
    "    revised_trainDataPartition = []\n",
    "    for i in range(len(trainDataPartition)):\n",
    "        trainset = trainDataPartition[i]\n",
    "        #print(trainset)\n",
    "        records = trainset[:,0] # record of labels\n",
    "        #print(sum(records == 1), sum(records == 0))\n",
    "        if sum(records == 1) == 0 or sum(records == 0) == 0:\n",
    "            revised_trainDataPartition.append(np.nan)\n",
    "        elif sum(records == 1) > sum(records == 0):\n",
    "            while sum(records == 1) >= 1.3 * sum(records == 0):\n",
    "                r = round(np.random.rand() * (trainset.shape[0]-1))\n",
    "                #print(r)\n",
    "                if records[r] == 1:\n",
    "                    trainset = np.delete(trainset, r, 0)\n",
    "                    records = np.delete(records, r)\n",
    "\n",
    "            revised_trainDataPartition.append(trainset)\n",
    "        else:\n",
    "            while sum(records == 1) <= 1.3 * sum(records == 0):\n",
    "                r = round(np.random.rand() * (trainset.shape[0]-1))\n",
    "                if records[r] == 0:\n",
    "                    trainset = np.delete(trainset, r, 0)\n",
    "                    records = np.delete(records, r)\n",
    "\n",
    "            revised_trainDataPartition.append(trainset)\n",
    "        #print(sum(records == 1), sum(records == 0))\n",
    "\n",
    "    group = len(revised_trainDataPartition)\n",
    "    print(group)\n",
    "    \n",
    "    return revised_trainDataPartition, valDataPartition, group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4 4\n"
     ]
    }
   ],
   "source": [
    "trainDataPartition, valDataPartition, group = time_cross(train, 0, 260, 100, 30)\n",
    "print(len(trainDataPartition), len(valDataPartition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>480</th>\n",
       "      <th>481</th>\n",
       "      <th>482</th>\n",
       "      <th>483</th>\n",
       "      <th>484</th>\n",
       "      <th>485</th>\n",
       "      <th>486</th>\n",
       "      <th>487</th>\n",
       "      <th>488</th>\n",
       "      <th>489</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1249.02</td>\n",
       "      <td>2.211</td>\n",
       "      <td>0.148873</td>\n",
       "      <td>0.340656</td>\n",
       "      <td>0.372116</td>\n",
       "      <td>1252.81</td>\n",
       "      <td>2.268</td>\n",
       "      <td>0.14969</td>\n",
       "      <td>0.340436</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1252.81</td>\n",
       "      <td>2.268</td>\n",
       "      <td>0.14969</td>\n",
       "      <td>0.340436</td>\n",
       "      <td>0.373081</td>\n",
       "      <td>1242.11</td>\n",
       "      <td>2.234</td>\n",
       "      <td>0.145837</td>\n",
       "      <td>0.340384</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1242.11</td>\n",
       "      <td>2.234</td>\n",
       "      <td>0.145837</td>\n",
       "      <td>0.340384</td>\n",
       "      <td>0.362818</td>\n",
       "      <td>1238.28</td>\n",
       "      <td>2.175</td>\n",
       "      <td>0.142869</td>\n",
       "      <td>0.340344</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1238.28</td>\n",
       "      <td>2.175</td>\n",
       "      <td>0.142869</td>\n",
       "      <td>0.340344</td>\n",
       "      <td>0.355873</td>\n",
       "      <td>1254.21</td>\n",
       "      <td>2.238</td>\n",
       "      <td>0.146492</td>\n",
       "      <td>0.340711</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1254.21</td>\n",
       "      <td>2.238</td>\n",
       "      <td>0.146492</td>\n",
       "      <td>0.340711</td>\n",
       "      <td>0.364272</td>\n",
       "      <td>1242.37</td>\n",
       "      <td>2.137</td>\n",
       "      <td>0.143138</td>\n",
       "      <td>0.340486</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1242.37</td>\n",
       "      <td>2.137</td>\n",
       "      <td>0.143138</td>\n",
       "      <td>0.340486</td>\n",
       "      <td>0.357629</td>\n",
       "      <td>1243.01</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.14312</td>\n",
       "      <td>0.340261</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1243.01</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.14312</td>\n",
       "      <td>0.340261</td>\n",
       "      <td>0.358019</td>\n",
       "      <td>1241.36</td>\n",
       "      <td>2.189</td>\n",
       "      <td>0.143166</td>\n",
       "      <td>0.340243</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1241.36</td>\n",
       "      <td>2.189</td>\n",
       "      <td>0.143166</td>\n",
       "      <td>0.340243</td>\n",
       "      <td>0.356439</td>\n",
       "      <td>1246.56</td>\n",
       "      <td>2.196</td>\n",
       "      <td>0.144719</td>\n",
       "      <td>0.340215</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1246.56</td>\n",
       "      <td>2.196</td>\n",
       "      <td>0.144719</td>\n",
       "      <td>0.340215</td>\n",
       "      <td>0.360829</td>\n",
       "      <td>1254.14</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.143025</td>\n",
       "      <td>0.340635</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1254.14</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.143025</td>\n",
       "      <td>0.340635</td>\n",
       "      <td>0.356761</td>\n",
       "      <td>1250.01</td>\n",
       "      <td>2.196</td>\n",
       "      <td>0.141733</td>\n",
       "      <td>0.340416</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 490 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  0        1      2         3         4         5        6      7         8    \\\n",
       "0   0  1249.02  2.211  0.148873  0.340656  0.372116  1252.81  2.268   0.14969   \n",
       "1   0  1252.81  2.268   0.14969  0.340436  0.373081  1242.11  2.234  0.145837   \n",
       "2   0  1242.11  2.234  0.145837  0.340384  0.362818  1238.28  2.175  0.142869   \n",
       "3   0  1238.28  2.175  0.142869  0.340344  0.355873  1254.21  2.238  0.146492   \n",
       "4   0  1254.21  2.238  0.146492  0.340711  0.364272  1242.37  2.137  0.143138   \n",
       "5   1  1242.37  2.137  0.143138  0.340486  0.357629  1243.01   2.13   0.14312   \n",
       "6   1  1243.01   2.13   0.14312  0.340261  0.358019  1241.36  2.189  0.143166   \n",
       "7   1  1241.36  2.189  0.143166  0.340243  0.356439  1246.56  2.196  0.144719   \n",
       "8   1  1246.56  2.196  0.144719  0.340215  0.360829  1254.14   2.15  0.143025   \n",
       "9   1  1254.14   2.15  0.143025  0.340635  0.356761  1250.01  2.196  0.141733   \n",
       "\n",
       "        9   ... 480 481 482 483 484 485 486 487 488 489  \n",
       "0  0.340436 ...  30  23  15   8  22  20   3   2   2  13  \n",
       "1  0.340384 ...  30  23  15   8  22  20   3   2   2  13  \n",
       "2  0.340344 ...  30  23  15   8  22  20   3   2   2  13  \n",
       "3  0.340711 ...  30  23  15   8  22  20   3   2   2  13  \n",
       "4  0.340486 ...  30  23  15   8  22  20   3   2   2  13  \n",
       "5  0.340261 ...  15  10  25  16  18  18   0   2   2  20  \n",
       "6  0.340243 ...  15  10  25  16  18  18   0   2   2  20  \n",
       "7  0.340215 ...  15  10  25  16  18  18   0   2   2  20  \n",
       "8  0.340635 ...  15  10  25  16  18  18   0   2   2  20  \n",
       "9  0.340416 ...  15  22  14  11  22  31   0   4   2  31  \n",
       "\n",
       "[10 rows x 490 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.DataFrame(valDataPartition[0])\n",
    "t.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forest Implementation\n",
    "No normalization necessary for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "### Try Random Forest Classifier\n",
    "\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf(train_list, val_list, group):\n",
    "    splits = group\n",
    "    score = []\n",
    "\n",
    "    #kf = sklearn.model_selection.KFold(n_splits=splits, random_state = 10, shuffle = True)\n",
    "    #kf.get_n_splits(features)\n",
    "\n",
    "    data_size = trainDataPartition[0].shape\n",
    "\n",
    "    for idx in range(len(trainDataPartition)-1):\n",
    "            # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "            #try:\n",
    "            X_train, y_train = trainDataPartition[idx][:,1:data_size[1]+1], trainDataPartition[idx][:,0]\n",
    "            y_train = y_train.astype('int')\n",
    "            #print(X_train)\n",
    "            X_test, y_test = valDataPartition[idx][:,1:data_size[1]+1], valDataPartition[idx][:,0]\n",
    "            y_test = y_test.astype('int')\n",
    "            print('train:', sum(y_train), len(y_train))\n",
    "            print('test:', sum(y_test), len(y_test))\n",
    "\n",
    "            # Fit the RF model\n",
    "            clf = RandomForestClassifier(n_estimators=50, max_depth=1500, random_state=0)\n",
    "            clf.fit(X_train, y_train)\n",
    "            #except:\n",
    "            #    continue # nan\n",
    "                \n",
    "            # print predicitions\n",
    "            pred = clf.predict(X_test)\n",
    "            #print(pred)\n",
    "\n",
    "            # add up AUROCs\n",
    "            \n",
    "            try:\n",
    "                temp_score = sklearn.metrics.roc_auc_score(y_test, pred)\n",
    "                #temp_score = sklearn.metrics.accuracy_score(y_test,pred)\n",
    "                #score = score + sklearn.metrics.accuracy_score(y_test, pred)\n",
    "                #temp_score = sum([1 for i in range(len(pred)) if pred[i] == y_test[i]]) / len(pred)\n",
    "                score.append(temp_score)\n",
    "                print(temp_score)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "    # calculate average\n",
    "    score = np.mean(score)\n",
    "    print(\"Averaged Score is: %0.4f\" % score, splits)\n",
    "\n",
    "\n",
    "    # print(clf.feature_importances_)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groups 4\n",
      "train: 139 246\n",
      "test: 43 99\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-839730615d4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'groups'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalDataPartition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainDataPartition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-48f94d9b3024>\u001b[0m in \u001b[0;36mrf\u001b[0;34m(train_list, val_list, group)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# Fit the RF model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;31m#except:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m#    continue # nan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m                 \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \"\"\"\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '.'"
     ]
    }
   ],
   "source": [
    "print('groups', group)\n",
    "rf(valDataPartition, trainDataPartition, group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 100 50\n",
      "38\n",
      "train: 29 51\n",
      "test: 26 49\n",
      "0.5192307692307693\n",
      "train: 41 72\n",
      "test: 18 49\n",
      "0.5\n",
      "train: 42 74\n",
      "test: 4 49\n",
      "0.7666666666666666\n",
      "train: 27 47\n",
      "test: 32 49\n",
      "0.5\n",
      "train: 30 53\n",
      "test: 17 49\n",
      "0.5\n",
      "train: 38 67\n",
      "test: 49 49\n",
      "train: 49 87\n",
      "test: 39 49\n",
      "0.5\n",
      "train: 32 57\n",
      "test: 25 49\n",
      "0.4275\n",
      "train: 18 32\n",
      "test: 31 49\n",
      "0.46236559139784955\n",
      "train: 44 78\n",
      "test: 25 49\n",
      "0.5\n",
      "train: 42 74\n",
      "test: 9 49\n",
      "0.5\n",
      "train: 55 100\n",
      "test: 27 49\n",
      "0.5\n",
      "train: 40 70\n",
      "test: 27 49\n",
      "0.5\n",
      "train: 32 56\n",
      "test: 39 49\n",
      "0.5897435897435898\n",
      "train: 41 73\n",
      "test: 42 49\n",
      "0.5\n",
      "train: 23 41\n",
      "test: 6 49\n",
      "0.5678294573643411\n",
      "train: 46 82\n",
      "test: 29 49\n",
      "0.375\n",
      "train: 44 77\n",
      "test: 41 49\n",
      "0.9268292682926829\n",
      "train: 45 79\n",
      "test: 22 49\n",
      "0.6456228956228957\n",
      "train: 42 75\n",
      "test: 44 49\n",
      "0.5\n",
      "train: 35 62\n",
      "test: 0 49\n",
      "train: 56 100\n",
      "test: 14 49\n",
      "0.5\n",
      "train: 33 58\n",
      "test: 12 49\n",
      "0.5765765765765765\n",
      "train: 20 35\n",
      "test: 14 49\n",
      "0.5\n",
      "train: 18 31\n",
      "test: 23 49\n",
      "0.5\n",
      "train: 38 67\n",
      "test: 29 49\n",
      "0.5077586206896552\n",
      "train: 38 67\n",
      "test: 32 49\n",
      "0.5\n",
      "train: 47 83\n",
      "test: 25 49\n",
      "0.4791666666666667\n",
      "train: 33 59\n",
      "test: 30 49\n",
      "0.5754385964912281\n",
      "train: 44 78\n",
      "test: 30 49\n",
      "0.5\n",
      "train: 54 100\n",
      "test: 27 49\n",
      "0.5\n",
      "train: 48 84\n",
      "test: 38 49\n",
      "0.4605263157894737\n",
      "train: 38 68\n",
      "test: 33 49\n",
      "0.5\n",
      "train: 23 41\n",
      "test: 24 49\n",
      "0.5\n",
      "train: 46 82\n",
      "test: 23 49\n",
      "0.6145484949832776\n",
      "train: 38 67\n",
      "test: 49 49\n",
      "train: 56 100\n",
      "test: 12 49\n",
      "0.617117117117117\n",
      "Averaged Score is: 0.5327 38\n",
      "100 100 100\n",
      "19\n",
      "train: 29 51\n",
      "test: 44 99\n",
      "0.5113636363636364\n",
      "train: 42 74\n",
      "test: 36 99\n",
      "0.3392857142857143\n",
      "train: 30 53\n",
      "test: 67 99\n",
      "0.5130597014925373\n",
      "train: 49 87\n",
      "test: 65 99\n",
      "0.5\n",
      "train: 18 32\n",
      "test: 57 99\n",
      "0.46491228070175444\n",
      "train: 42 74\n",
      "test: 36 99\n",
      "0.5\n",
      "train: 40 70\n",
      "test: 67 99\n",
      "0.5\n",
      "train: 41 73\n",
      "test: 48 99\n",
      "0.5\n",
      "train: 46 82\n",
      "test: 70 99\n",
      "0.3812807881773399\n",
      "train: 45 79\n",
      "test: 67 99\n",
      "0.4986007462686567\n",
      "train: 35 62\n",
      "test: 14 99\n",
      "0.5\n",
      "train: 33 58\n",
      "test: 26 99\n",
      "0.577713382507903\n",
      "train: 18 31\n",
      "test: 52 99\n",
      "0.425531914893617\n",
      "train: 38 67\n",
      "test: 58 99\n",
      "0.5\n",
      "train: 33 59\n",
      "test: 61 99\n",
      "0.39214840379637617\n",
      "train: 54 100\n",
      "test: 66 99\n",
      "0.5\n",
      "train: 38 68\n",
      "test: 57 99\n",
      "0.4768170426065163\n",
      "train: 46 82\n",
      "test: 73 99\n",
      "0.7118018967334037\n",
      "Averaged Score is: 0.4885 19\n",
      "260 100 260\n",
      "8\n",
      "train: 29 51\n",
      "test: 108 259\n",
      "0.6042739759627177\n",
      "train: 38 67\n",
      "test: 171 259\n",
      "0.5175438596491229\n",
      "train: 48 84\n",
      "test: 140 259\n",
      "0.4560924369747899\n",
      "train: 22 39\n",
      "test: 141 259\n",
      "0.6600552951075851\n",
      "train: 50 89\n",
      "test: 93 259\n",
      "0.48299650213758255\n",
      "train: 38 67\n",
      "test: 158 259\n",
      "0.5\n",
      "train: 44 77\n",
      "test: 166 259\n",
      "0.48383858012695946\n",
      "Averaged Score is: 0.5293 8\n",
      "50 252 50\n",
      "35\n",
      "train: 91 160\n",
      "test: 31 49\n",
      "0.5\n",
      "train: 80 141\n",
      "test: 19 49\n",
      "0.5\n",
      "train: 100 176\n",
      "test: 49 49\n",
      "train: 101 178\n",
      "test: 39 49\n",
      "0.5\n",
      "train: 135 252\n",
      "test: 25 49\n",
      "0.5\n",
      "train: 119 211\n",
      "test: 31 49\n",
      "0.4632616487455197\n",
      "train: 106 188\n",
      "test: 26 49\n",
      "0.5\n",
      "train: 116 206\n",
      "test: 7 49\n",
      "0.4880952380952381\n",
      "train: 116 206\n",
      "test: 27 49\n",
      "0.5993265993265993\n",
      "train: 127 252\n",
      "test: 29 49\n",
      "0.5344827586206896\n",
      "train: 110 194\n",
      "test: 39 49\n",
      "0.5384615384615384\n",
      "train: 129 252\n",
      "test: 40 49\n",
      "0.5\n",
      "train: 132 234\n",
      "test: 6 49\n",
      "0.5\n",
      "train: 138 252\n",
      "test: 29 49\n",
      "0.3741379310344828\n",
      "train: 127 225\n",
      "test: 43 49\n",
      "0.7868217054263567\n",
      "train: 128 227\n",
      "test: 22 49\n",
      "0.5042087542087542\n",
      "train: 128 227\n",
      "test: 42 49\n",
      "0.7380952380952381\n",
      "train: 140 248\n",
      "test: 0 49\n",
      "train: 141 250\n",
      "test: 14 49\n",
      "0.65\n",
      "train: 133 252\n",
      "test: 12 49\n",
      "0.6621621621621622\n",
      "train: 118 208\n",
      "test: 16 49\n",
      "0.5625\n",
      "train: 82 145\n",
      "test: 21 49\n",
      "0.5\n",
      "train: 85 150\n",
      "test: 31 49\n",
      "0.6944444444444444\n",
      "train: 65 114\n",
      "test: 32 49\n",
      "0.5\n",
      "train: 98 173\n",
      "test: 25 49\n",
      "0.5\n",
      "train: 119 210\n",
      "test: 31 49\n",
      "0.6648745519713262\n",
      "train: 136 241\n",
      "test: 30 49\n",
      "0.5\n",
      "train: 134 252\n",
      "test: 27 49\n",
      "0.5\n",
      "train: 124 220\n",
      "test: 38 49\n",
      "0.5885167464114832\n",
      "train: 122 216\n",
      "test: 31 49\n",
      "0.4605734767025089\n",
      "train: 114 202\n",
      "test: 24 49\n",
      "0.3816666666666666\n",
      "train: 123 218\n",
      "test: 25 49\n",
      "0.5983333333333334\n",
      "train: 136 241\n",
      "test: 49 49\n",
      "train: 113 200\n",
      "test: 10 49\n",
      "0.6307692307692307\n",
      "Averaged Score is: 0.5458 35\n",
      "100 252 100\n",
      "18\n",
      "train: 91 160\n",
      "test: 50 99\n",
      "0.5420408163265306\n",
      "train: 100 176\n",
      "test: 89 99\n",
      "0.3539325842696629\n",
      "train: 135 252\n",
      "test: 56 99\n",
      "0.5\n",
      "train: 106 188\n",
      "test: 34 99\n",
      "0.5307692307692308\n",
      "train: 116 206\n",
      "test: 56 99\n",
      "0.5232558139534884\n",
      "train: 110 194\n",
      "test: 80 99\n",
      "0.5\n",
      "train: 132 234\n",
      "test: 35 99\n",
      "0.5\n",
      "train: 127 225\n",
      "test: 66 99\n",
      "0.5\n",
      "train: 128 227\n",
      "test: 42 99\n",
      "0.5\n",
      "train: 141 250\n",
      "test: 26 99\n",
      "0.6580611169652264\n",
      "train: 118 208\n",
      "test: 38 99\n",
      "0.5\n",
      "train: 85 150\n",
      "test: 64 99\n",
      "0.4921875\n",
      "train: 98 173\n",
      "test: 56 99\n",
      "0.5784883720930233\n",
      "train: 136 241\n",
      "test: 58 99\n",
      "0.5\n",
      "train: 124 220\n",
      "test: 70 99\n",
      "0.48374384236453194\n",
      "train: 114 202\n",
      "test: 49 99\n",
      "0.2724489795918368\n",
      "train: 136 241\n",
      "test: 60 99\n",
      "0.5\n",
      "Averaged Score is: 0.4962 18\n",
      "260 252 260\n",
      "7\n",
      "train: 91 160\n",
      "test: 167 259\n",
      "0.5248633168445718\n",
      "train: 110 195\n",
      "test: 136 259\n",
      "0.5327594452415112\n",
      "train: 112 198\n",
      "test: 157 259\n",
      "0.5504246284501062\n",
      "train: 118 209\n",
      "test: 86 259\n",
      "0.5057803468208093\n",
      "train: 87 153\n",
      "test: 148 259\n",
      "0.5045045045045046\n",
      "train: 136 241\n",
      "test: 153 259\n",
      "0.5333579972869651\n",
      "Averaged Score is: 0.5253 7\n",
      "50 410 50\n",
      "32\n",
      "train: 173 306\n",
      "test: 38 49\n",
      "0.5\n",
      "train: 191 337\n",
      "test: 19 49\n",
      "0.5\n",
      "train: 228 410\n",
      "test: 30 49\n",
      "0.5719298245614035\n",
      "train: 208 410\n",
      "test: 30 49\n",
      "0.6307017543859649\n",
      "train: 226 410\n",
      "test: 9 49\n",
      "0.6777777777777778\n",
      "train: 228 404\n",
      "test: 22 49\n",
      "0.5740740740740741\n",
      "train: 228 404\n",
      "test: 37 49\n",
      "0.2736486486486487\n",
      "train: 228 404\n",
      "test: 39 49\n",
      "0.5\n",
      "train: 220 390\n",
      "test: 32 49\n",
      "0.5\n",
      "train: 219 388\n",
      "test: 10 49\n",
      "0.6987179487179488\n",
      "train: 216 410\n",
      "test: 24 49\n",
      "0.7325\n",
      "train: 223 410\n",
      "test: 46 49\n",
      "0.4673913043478261\n",
      "train: 227 410\n",
      "test: 25 49\n",
      "0.4741666666666666\n",
      "train: 231 410\n",
      "test: 34 49\n",
      "0.5\n",
      "train: 194 344\n",
      "test: 2 49\n",
      "0.5\n",
      "train: 209 370\n",
      "test: 14 49\n",
      "0.6714285714285714\n",
      "train: 221 410\n",
      "test: 9 49\n",
      "0.5\n",
      "train: 190 336\n",
      "test: 22 49\n",
      "0.42592592592592593\n",
      "train: 173 306\n",
      "test: 15 49\n",
      "0.4431372549019607\n",
      "train: 187 330\n",
      "test: 35 49\n",
      "0.6142857142857143\n",
      "train: 171 302\n",
      "test: 35 49\n",
      "0.6000000000000001\n",
      "train: 170 300\n",
      "test: 27 49\n",
      "0.5454545454545454\n",
      "train: 165 291\n",
      "test: 30 49\n",
      "0.5157894736842105\n",
      "train: 179 316\n",
      "test: 26 49\n",
      "0.3896321070234114\n",
      "train: 186 329\n",
      "test: 34 49\n",
      "0.6205882352941177\n",
      "train: 203 359\n",
      "test: 38 49\n",
      "0.47368421052631576\n",
      "train: 220 390\n",
      "test: 24 49\n",
      "0.4649999999999999\n",
      "train: 206 365\n",
      "test: 22 49\n",
      "0.5\n",
      "train: 180 319\n",
      "test: 33 49\n",
      "0.7850378787878788\n",
      "train: 224 397\n",
      "test: 46 49\n",
      "0.75\n",
      "train: 202 358\n",
      "test: 6 49\n",
      "0.5193798449612403\n",
      "Averaged Score is: 0.5458 32\n",
      "100 410 100\n",
      "16\n",
      "train: 173 306\n",
      "test: 58 99\n",
      "0.5\n",
      "train: 228 410\n",
      "test: 60 99\n",
      "0.6910256410256411\n",
      "train: 226 410\n",
      "test: 31 99\n",
      "0.685483870967742\n",
      "train: 228 404\n",
      "test: 77 99\n",
      "0.30844155844155846\n",
      "train: 220 390\n",
      "test: 43 99\n",
      "0.6754568106312292\n",
      "train: 216 410\n",
      "test: 71 99\n",
      "0.6360663983903421\n",
      "train: 227 410\n",
      "test: 60 99\n",
      "0.4602564102564103\n",
      "train: 194 344\n",
      "test: 16 99\n",
      "0.5\n",
      "train: 221 410\n",
      "test: 31 99\n",
      "0.5\n",
      "train: 173 306\n",
      "test: 50 99\n",
      "0.6544897959183673\n",
      "train: 171 302\n",
      "test: 62 99\n",
      "0.3984306887532694\n",
      "train: 165 291\n",
      "test: 56 99\n",
      "0.44622093023255816\n",
      "train: 186 329\n",
      "test: 73 99\n",
      "0.48287671232876717\n",
      "train: 220 390\n",
      "test: 47 99\n",
      "0.4142798690671031\n",
      "train: 180 319\n",
      "test: 80 99\n",
      "0.5427631578947368\n",
      "Averaged Score is: 0.5264 16\n",
      "260 410 260\n",
      "6\n",
      "train: 173 306\n",
      "test: 129 259\n",
      "0.6381932021466905\n",
      "train: 228 404\n",
      "test: 162 259\n",
      "0.4740677103220059\n",
      "train: 209 410\n",
      "test: 126 259\n",
      "0.6075605680868839\n",
      "train: 229 410\n",
      "test: 112 259\n",
      "0.5042517006802721\n",
      "train: 166 293\n",
      "test: 164 259\n",
      "0.43899229781771504\n",
      "Averaged Score is: 0.5326 6\n",
      "[[1 2 2]]\n",
      "[[[0.53270355 0.48847308 0.52925724]\n",
      "  [0.54583007 0.49617225 0.52528171]\n",
      "  [0.54581457 0.52638612 0.5326131 ]]]\n"
     ]
    }
   ],
   "source": [
    "### Test\n",
    "# time_shift, size_train_set, size_val_set\n",
    "\n",
    "time_shift = [0] # smaller time shift is better, smaller training set, smaller val set 0, 50, 100, 126, 252, 504\n",
    "# 504 252 50 0.61268998\n",
    "size_train_set = [100, 252, 410]\n",
    "size_val_set = [50, 100, 260] # predict a month ahead (shift labels)\n",
    "\n",
    "score_matrix = np.zeros((len(time_shift), len(size_train_set), len(size_val_set)))\n",
    "\n",
    "for i in range(len(time_shift)):\n",
    "    for j in range(len(size_train_set)):\n",
    "        for k in range(len(size_val_set)):\n",
    "            time_shift = size_val_set[k]\n",
    "            print(time_shift, size_train_set[j], size_val_set[k])\n",
    "            trainDataPartition, valDataPartition, group = time_cross(train, time_shift, size_train_set[j], size_val_set[k], 30)\n",
    "\n",
    "            #time_shift[i]\n",
    "            score_matrix[i][j][k] = rf(valDataPartition, trainDataPartition, group)\n",
    "\n",
    "print(np.argmax(score_matrix, axis = 1))\n",
    "print(score_matrix)\n",
    "#0.61268998 Didn't work so well with Label 2\n",
    "# Perfomed well with predicting next day with Google Trends 0.8975, best was 0.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54583007, 0.52638612, 0.5326131 ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.max(score_matrix, axis = 1)\n",
    "#print(np.argmax(t, axis = 1))\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look for Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "trainDataPartition, valDataPartition, group = time_cross(train, 0, 252, 50, 30) #10 252 100 Draft_Google_shorter 0.8795"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 91 160\n",
      "test: 31 49\n",
      "0.5833333333333333\n",
      "train: 113 200\n",
      "test: 23 49\n",
      "0.6454849498327758\n",
      "train: 141 252\n",
      "test: 24 49\n",
      "0.4841666666666667\n",
      "train: 122 215\n",
      "test: 14 49\n",
      "0.5\n",
      "train: 140 248\n",
      "test: 28 49\n",
      "0.5\n",
      "train: 105 186\n",
      "test: 6 49\n",
      "0.5542635658914729\n",
      "Averaged Score is: 0.5445 7\n"
     ]
    }
   ],
   "source": [
    "splits = group\n",
    "score_list = []\n",
    "indices = []\n",
    "pred_labels = []\n",
    "\n",
    "data_size = trainDataPartition[0].shape\n",
    "\n",
    "for idx in range(len(trainDataPartition)-1):\n",
    "    try:\n",
    "        # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, y_train = trainDataPartition[idx][:,1:data_size[1]+1], trainDataPartition[idx][:,0]\n",
    "        y_train = y_train.astype('int')\n",
    "        #print(X_train)\n",
    "        X_test, y_test = valDataPartition[idx][:,1:data_size[1]+1], valDataPartition[idx][:,0]\n",
    "        y_test = y_test.astype('int')\n",
    "        print('train:', sum(y_train), len(y_train))\n",
    "        print('test:', sum(y_test), len(y_test))\n",
    "    \n",
    "        # Fit the RF model\n",
    "        clf = RandomForestClassifier(n_estimators=100, max_depth=1500, random_state=0) # previously 7\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # print predicitions\n",
    "        pred = clf.predict(X_test)\n",
    "        pred_labels.append(pred)\n",
    "        #print(pred)\n",
    "    except:\n",
    "        continue #np.nan\n",
    "        \n",
    "    # add up AUROCs\n",
    "            \n",
    "    try:\n",
    "        temp_score = sklearn.metrics.roc_auc_score(y_test, pred)\n",
    "        score_list.append(temp_score)\n",
    "        indices.append(idx)\n",
    "        print(temp_score)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "# calculate average\n",
    "score = np.mean(score_list)\n",
    "print(\"Averaged Score is: %0.4f\" % score, splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the accuracy through time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation: 0.05686521477316641\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb698080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(\"Standard Deviation:\", np.std(score_list))\n",
    "plt.figure()\n",
    "plt.plot(indices, score_list)\n",
    "plt.title('Performance across Folds')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which features are important during the time when the datasets are accurate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [x for x in range(len(score_list)) if score_list[x] > 0.75]\n",
    "importance = np.array([])\n",
    "count = 0\n",
    "\n",
    "for idx in range(1220, 1235): # for several months of 2012, May - end of November, 1180, 1281\n",
    "    # run random forest\n",
    "    try:\n",
    "\n",
    "        X_train, y_train = trainDataPartition[idx][:,1:data_size[1]+1], trainDataPartition[idx][:,0]\n",
    "        y_train = y_train.astype('int')\n",
    "\n",
    "        X_test, y_test = valDataPartition[idx][:,1:data_size[1]+1], valDataPartition[idx][:,0]\n",
    "        y_test = y_test.astype('int')\n",
    "    \n",
    "        # Fit the RF model\n",
    "        clf = RandomForestClassifier(n_estimators=20, max_depth=1500, random_state=0) # previously 7\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # print predicitions\n",
    "        pred = clf.predict(X_test)\n",
    "    \n",
    "        if not importance.any():\n",
    "            print('hi')\n",
    "            importance = clf.feature_importances_\n",
    "        else:\n",
    "            importance = importance + clf.feature_importances_\n",
    "\n",
    "        count+=1\n",
    "    except:\n",
    "        continue #np.nan\n",
    "\n",
    "    try:\n",
    "        temp_score = sklearn.metrics.roc_auc_score(y_test, pred)\n",
    "        score_list.append(temp_score)\n",
    "        indices.append(idx)\n",
    "        print(temp_score)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-695aba60efc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Feature importances\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m plt.bar(range(X_train.shape[1]), importance[feature_indices],\n\u001b[1;32m----> 8\u001b[1;33m        color=\"r\", align=\"center\") # X_train.shape[1]\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_indices\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#X_train.shape[1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#X_train.shape[1]])\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mbar\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                       mplDeprecation)\n\u001b[0;32m   2647\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1715\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[0;32m   1716\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1717\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1718\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1719\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mbar\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2015\u001b[0m         x, height, width, y, linewidth = np.broadcast_arrays(\n\u001b[0;32m   2016\u001b[0m             \u001b[1;31m# Make args iterable too.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2017\u001b[1;33m             np.atleast_1d(x), height, width, y, linewidth)\n\u001b[0m\u001b[0;32m   2018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2019\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0morientation\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'vertical'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_arrays\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_broadcast_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\lib\\stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_shape\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;31m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m     \u001b[1;31m# consistently\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m     \u001b[1;31m# unfortunately, it cannot handle 32 or more arguments directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m31\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xda7b550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importance = importance / count\n",
    "feature_indices = np.argsort(importance)[::-1]\n",
    "\n",
    "# Plot the feature importances of the forest (ERROR HIDDEN, TOO BIG)\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train.shape[1]), importance[feature_indices],\n",
    "       color=\"r\", align=\"center\") # X_train.shape[1]\n",
    "plt.xticks(range(X_train.shape[1]), feature_indices) #X_train.shape[1]\n",
    "plt.xlim([-1, 100]) #X_train.shape[1]]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Combined_Sets_from_Revised_3.csv'\n",
    "df = pd.read_csv(name)\n",
    "df = df.drop(['Date'], axis = 1)\n",
    "\n",
    "# Show all the list of features and their respective importances\n",
    "\n",
    "#listoffeatures = list(train_pd)[1:]\n",
    "listoffeatures = list(df)\n",
    "shortlist = []\n",
    "\n",
    "print('Top Features listed by Importance')\n",
    "\n",
    "for i in range(len(feature_indices)-1):\n",
    "    idx = feature_indices[i]\n",
    "    print(listoffeatures[idx], importance[idx])\n",
    "    if i <= 25:\n",
    "        shortlist.append(listoffeatures[idx])\n",
    "shortlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xdaad0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a graph of fetaure importances\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plot the feature importances of the forest (ERROR HIDDEN, TOO BIG)\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(100), importances[indices[0:100]],\n",
    "       color=\"r\", yerr=std[indices[0:100]], align=\"center\") # X_train.shape[1]\n",
    "plt.xticks(range(100), indices[0:100]) #X_train.shape[1]\n",
    "plt.xlim([-1, 100]) #X_train.shape[1]]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217\n",
      "218\n"
     ]
    }
   ],
   "source": [
    "print(len(clf.feature_importances_))\n",
    "print(len(list(train_pd)[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '../Data/Combined_Sets_from_Revised_3.csv'\n",
    "df = pd.read_csv(name)\n",
    "df = df.drop(['Date'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Features listed by Importance\n",
      "main56 0.04246516422174906\n",
      "main66 0.038890888318713866\n",
      "main81 0.03352209371117746\n",
      "main31 0.03316343824589267\n",
      "main71 0.029538007701172927\n",
      "main61 0.027638836562973338\n",
      "main96 0.026174527778898057\n",
      "main41 0.024717976602409993\n",
      "main33 0.022179143584261544\n",
      "main86 0.02192126337972254\n",
      "google_hits40 0.018536965272188975\n",
      "main26 0.018094151121507362\n",
      "main51 0.017907962611983155\n",
      "main53 0.01662669776174378\n",
      "main46 0.015511696529390826\n",
      "main6 0.015034778619333933\n",
      "invest5 0.014968034625538185\n",
      "google_hits53 0.014830217360014095\n",
      "main28 0.01446104855036105\n",
      "main36 0.013716114196511751\n",
      "main48 0.01369902198463893\n",
      "main93 0.012202968050008907\n",
      "main76 0.011880261213021217\n",
      "main73 0.010328238974565888\n",
      "main16 0.010052793341765304\n",
      "main19 0.009764406723616902\n",
      "invest3 0.009464639641187931\n",
      "main11 0.00859702479350911\n",
      "main88 0.008526362192154482\n",
      "main39 0.008260623177502284\n",
      "main24 0.008066004010519183\n",
      "main82 0.007844714248476117\n",
      "gfp8 0.007815534136366665\n",
      "main87 0.007041696130779015\n",
      "google_hits65 0.006967652742487809\n",
      "google_hits20 0.006902302692713001\n",
      "main2 0.006800220422439751\n",
      "main38 0.006738662783590923\n",
      "invest1 0.006597739086418496\n",
      "main52 0.006339177248413949\n",
      "invest7 0.006307781484506752\n",
      "main58 0.006137931478150553\n",
      "main54 0.0060628722019664535\n",
      "main30 0.005982808348576838\n",
      "main77 0.005828524516943372\n",
      "main98 0.005702826660309271\n",
      "google_hits1 0.005663721061424887\n",
      "google_hits12 0.005563208157980285\n",
      "gfp7 0.00548422924096102\n",
      "main59 0.005466601014086998\n",
      "main42 0.005196900152777917\n",
      "google_hits3 0.005152276044183217\n",
      "main44 0.005150007039899013\n",
      "main72 0.005074676182816275\n",
      "main63 0.005029383262084828\n",
      "main10 0.004945854569618633\n",
      "vix18 0.004797443339778451\n",
      "main18 0.004714812437907577\n",
      "Label4 0.00470369689279444\n",
      "main1 0.004644546373997585\n",
      "main99 0.004527986106514567\n",
      "main95 0.0043830395208108225\n",
      "google_hits0 0.004073396961495436\n",
      "vix9 0.004059169379505675\n",
      "main67 0.004032692683430712\n",
      "main91 0.004028929423588098\n",
      "vix1 0.00402515245626404\n",
      "main92 0.0040232218743024226\n",
      "main43 0.00401571890577654\n",
      "vix0 0.003939623780565347\n",
      "main34 0.0038822913547981487\n",
      "main68 0.003802651361683539\n",
      "main20 0.0037648070900256785\n",
      "main7 0.003759244533217392\n",
      "main29 0.0036656377887703774\n",
      "main5 0.0036636422302611816\n",
      "main64 0.003641033385107274\n",
      "main94 0.0035885108172296265\n",
      "main49 0.0035316821411182776\n",
      "main27 0.0035173712999337016\n",
      "google_hits35 0.003471247199402539\n",
      "gfp5 0.003456021943672014\n",
      "main47 0.003445145251149178\n",
      "google_hits43 0.003403563964839724\n",
      "vix16 0.0033554692108385326\n",
      "main22 0.003316328415358485\n",
      "google_hits49 0.0032464408121827258\n",
      "main15 0.0032103601363147136\n",
      "main37 0.0030942871372572696\n",
      "main17 0.003086096631638091\n",
      "main3 0.003067301295346146\n",
      "main85 0.00303931838657808\n",
      "main35 0.0030255478676819436\n",
      "main74 0.002999369153542762\n",
      "main4 0.0028407014921798053\n",
      "vix13 0.0028321760797555963\n",
      "main32 0.0028196904109299386\n",
      "main84 0.0028106539461164332\n",
      "invest0 0.0027952976449841897\n",
      "vix8 0.002738965492595124\n",
      "main78 0.0027267734923204705\n",
      "main45 0.0027262499405578417\n",
      "gfp0 0.002706027812218724\n",
      "main25 0.0026991280660191635\n",
      "vix2 0.002682960569055477\n",
      "main13 0.002655515444249283\n",
      "main23 0.0025986793925946404\n",
      "main9 0.002597453068736458\n",
      "vix10 0.0025622912016360355\n",
      "main14 0.002541476139927028\n",
      "gfp6 0.0024359672060920135\n",
      "google_hits36 0.0023466381249853956\n",
      "main69 0.0023417365217135583\n",
      "main75 0.002326799991991365\n",
      "google_hits41 0.0022938901601567137\n",
      "google_hits55 0.0022017612430552196\n",
      "google_hits46 0.002191289182091685\n",
      "main89 0.0021638608236840425\n",
      "main40 0.0021448310781357702\n",
      "google_hits14 0.002119607647941866\n",
      "main57 0.002102774380961217\n",
      "main12 0.002087364849299131\n",
      "main90 0.0020825736447060528\n",
      "vix12 0.002075792526924986\n",
      "vix17 0.002055264110711405\n",
      "google_hits8 0.0020351104948871015\n",
      "vix6 0.001980222013967345\n",
      "google_hits16 0.0018986514158922494\n",
      "gfp4 0.0018977718330979187\n",
      "main70 0.001873467870843899\n",
      "rdi0 0.0018079115529388839\n",
      "vix11 0.0017768750622082052\n",
      "google_hits26 0.0017639654445704383\n",
      "vix15 0.0017318116909896212\n",
      "main62 0.001726250660094476\n",
      "vix4 0.0016725469298374917\n",
      "invest8 0.0016504855635974276\n",
      "invest12 0.0015290493868347593\n",
      "main0 0.0015067575908122755\n",
      "google_hits28 0.0014288303853314957\n",
      "invest14 0.0013963755876898803\n",
      "cci0 0.0013763729265254946\n",
      "invest9 0.0013735351345612384\n",
      "vix3 0.001294758570116214\n",
      "vix7 0.001269725371730423\n",
      "main83 0.0011486006284853036\n",
      "main97 0.0011105719612005598\n",
      "google_hits15 0.0011046576325825779\n",
      "google_hits42 0.0011006502919880898\n",
      "main65 0.0010965310360449608\n",
      "main60 0.0010736784598493572\n",
      "vix5 0.0010628951798793704\n",
      "main8 0.001051479470812033\n",
      "gfp3 0.0009969655797554666\n",
      "gfp2 0.000965950447795599\n",
      "main80 0.0009654015186774373\n",
      "google_hits11 0.0009593027609585864\n",
      "main50 0.000943181082521658\n",
      "main55 0.0009354148792477555\n",
      "main21 0.0008936841327753135\n",
      "google_hits45 0.0008705605624963544\n",
      "google_hits7 0.0008471130356327895\n",
      "invest13 0.0008263382853872618\n",
      "google_hits37 0.0007610893041427097\n",
      "gfp1 0.0007076204665326055\n",
      "google_hits58 0.0006218023255813958\n",
      "vix14 0.000571428956363824\n",
      "google_hits51 0.0005701161770140432\n",
      "google_hits48 0.0005579085266585267\n",
      "google_hits5 0.0005564701414010599\n",
      "google_hits27 0.0005495328641138614\n",
      "invest15 0.00053950576768973\n",
      "invest4 0.0004541591839841816\n",
      "main79 0.00040620922140060904\n",
      "google_hits17 0.00036046511627906973\n",
      "invest11 0.00030692670936438847\n",
      "google_hits6 0.0002868710237131289\n",
      "gfp9 0.0002170868347338936\n",
      "invest6 0.00020172953417196837\n",
      "invest10 0.00016450471698113207\n",
      "google_hits10 0.00015071417394997493\n",
      "google_hits54 0.00010905253283302064\n",
      "google_hits25 9.277633765982651e-05\n",
      "invest2 1.9320647409485103e-05\n",
      "google_hits66 5.6140083917407375e-06\n",
      "google_hits24 0.0\n",
      "google_hits23 0.0\n",
      "google_hits64 0.0\n",
      "google_hits63 0.0\n",
      "google_hits62 0.0\n",
      "google_hits61 0.0\n",
      "google_hits60 0.0\n",
      "google_hits59 0.0\n",
      "vix19 0.0\n",
      "google_hits57 0.0\n",
      "cpi0 0.0\n",
      "google_hits56 0.0\n",
      "google_hits2 0.0\n",
      "google_hits52 0.0\n",
      "google_hits4 0.0\n",
      "google_hits50 0.0\n",
      "google_hits9 0.0\n",
      "google_hits47 0.0\n",
      "google_hits13 0.0\n",
      "google_hits44 0.0\n",
      "google_hits18 0.0\n",
      "google_hits39 0.0\n",
      "google_hits38 0.0\n",
      "google_hits19 0.0\n",
      "google_hits22 0.0\n",
      "google_hits34 0.0\n",
      "google_hits33 0.0\n",
      "google_hits32 0.0\n",
      "google_hits31 0.0\n",
      "google_hits30 0.0\n",
      "google_hits29 0.0\n"
     ]
    }
   ],
   "source": [
    "# Show all the list of features and their respective importances\n",
    "\n",
    "#listoffeatures = list(train_pd)[1:]\n",
    "listoffeatures = list(df)\n",
    "shortlist = []\n",
    "\n",
    "print('Top Features listed by Importance')\n",
    "\n",
    "for i in range(len(indices)-1):\n",
    "    idx = indices[i]\n",
    "    print(listoffeatures[idx], importances[idx])\n",
    "#    if i <= 50:\n",
    "#        shortlist.append(listoffeatures[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "trainDataPartition, valDataPartition, group = time_cross(train, 0, 410, 50) #10 252 100 Draft_Google_shorter 0.8795"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(valDataPartition[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 173 306\n",
      "test: 40 49\n",
      "train: 219 388\n",
      "test: 12 49\n",
      "train: 178 314\n",
      "test: 23 49\n",
      "train: 205 363\n",
      "test: 22 49\n",
      "Averaged Score is: nan 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "splits = group\n",
    "score = []\n",
    "good_sets = []\n",
    "gammas = []\n",
    "\n",
    "data_size = trainDataPartition[0].shape\n",
    "\n",
    "for idx in range(len(trainDataPartition)-1):\n",
    "    try:\n",
    "        # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, y_train = trainDataPartition[idx][:,1:data_size[1]+1], trainDataPartition[idx][:,0]\n",
    "        y_train = y_train.astype('int')\n",
    "        #print(X_train)\n",
    "        X_test, y_test = valDataPartition[idx][:,1:data_size[1]+1], valDataPartition[idx][:,0]\n",
    "        y_test = y_test.astype('int')\n",
    "        print('train:', sum(y_train), len(y_train))\n",
    "        print('test:', sum(y_test), len(y_test))\n",
    "        #print(1 / (X_train.shape[1] * X_train.var()))\n",
    "        # Fit the RF model\n",
    "\n",
    "        #gamma =  (1 / (X_train.shape[1] * X_train.var()))\n",
    "        clf = sklearn.svm.SVC(C=.7, kernel='rbf', gamma='scale') # previously 7\n",
    "        clf.fit(X_train, y_train)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    # print predicitions\n",
    "    pred = clf.predict(X_test)\n",
    "    #print(pred)\n",
    "\n",
    "    # add up AUROCs\n",
    "            \n",
    "    try:\n",
    "        temp_score = sklearn.metrics.roc_auc_score(y_test, pred)\n",
    "        score.append(temp_score)\n",
    "        print(temp_score)\n",
    "        if temp_score > 0.7:\n",
    "            good_sets.append(idx)\n",
    "            gammas.append(1 / (X_train.shape[1] * X_train.var()))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "# calculate average\n",
    "score = np.mean(score)\n",
    "print(\"Averaged Score is: %0.4f\" % score, splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels2 = []\n",
    "for predlist in pred_labels:\n",
    "    for x in range(len(predlist)):\n",
    "        pred_labels2.append(predlist[x])\n",
    "pred_labels2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test just one giant set\n",
    "Why: Because if we can get more than 50%, we can get predictions for everything in the training set. Let's see if we can get some kind of \"universal\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7120, 219)"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file1 = \"Combined_Sets_from_Revised_3_Label1.csv\" #\"Draft_Google_Shorter.csv\" #Removed Missing\n",
    "\n",
    "train_pd = pd.read_csv(file1)\n",
    "train_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(936, 219)"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pd = train_pd[6184:]\n",
    "\n",
    "train = np.array(train_pd)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 786.5599980000001, 2.908, ..., 0.0, 0.0, 26.0],\n",
       "       [1.0, 789.5, 2.891, ..., 0.0, 0.0, 26.0],\n",
       "       [1.0, 783.119995, 2.944, ..., 0.0, 0.0, 26.0],\n",
       "       ...,\n",
       "       [1.0, 683.849976, 1.9669999999999999, ..., 1.0, 1.0, 36.0],\n",
       "       [1.0, 705.049988, 1.9580000000000002, ..., 1.0, 1.0, 36.0],\n",
       "       [1.0, 706.179993, 1.996, ..., 1.0, 1.0, 36.0]], dtype=object)"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valDataPartition[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
